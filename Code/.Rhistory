corrplot(cor_matrix, method = "color", col = colorRampPalette(c("darkblue", "white", "darkred"))(100),
addCoef.col = "black", tl.cex = 0.8, tl.srt = 45)
# Select numerical variables for correlation analysis
numerical_variables <- c("age", "avg_glucose_level", "bmi")
# Create an empty data frame to store correlation results
cor_data_long <- data.frame()
# Loop through numerical variables and calculate correlations
for (variable in numerical_variables) {
correlation_result <- cor.test(stroke[[variable]], stroke$stroke, method = "spearman")
# Append results to the data frame
cor_data_long <- rbind(cor_data_long, data.frame(
variable = variable,
correlation = correlation_result$estimate,
p_value = correlation_result$p.value
))
}
# Create a bar plot
ggplot(cor_data_long, aes(x = variable, y = correlation, fill = variable)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Correlation with Stroke", x = "Variable", y = "Correlation") +
scale_fill_manual(values = c("lightblue", "lightgreen", "lightcoral")) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Assuming your dataset is stored in a variable named 'data'
# Extract features (X) and target variable (y)
X <- stroke[, !(names(stroke) %in% c("stroke"))]
y <- stroke$stroke
# Data preprocessing (handle missing values, encode categorical variables, etc.)
# Split the dataset into training and testing sets
set.seed(42)  # for reproducibility
split_index <- createDataPartition(y, p = 0.8, list = FALSE)
train_data <- stroke[split_index, ]
test_data <- stroke[-split_index, ]
# Create and train the Naive Bayes model
model <- naiveBayes(stroke ~ ., data = train_data, laplace = 1)
model
# laplace smoothing, adjust as needed
# ...
# Make predictions on the testing set
predictions <- predict(model, newdata = test_data)
# Evaluate the model
conf_matrix <- table(predictions, test_data$stroke)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Accuracy:", accuracy, "\n")
# Display confusion matrix for more detailed metrics
print(conf_matrix)
# Assuming 'predictions' and 'test_data$stroke' are probabilities
roc_curve <- roc(test_data$stroke, as.numeric(predictions == 1))
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)
## Find the dimension of the dataset
dim(stroke)
## Count missing values in each column
null_counts <- colSums(is.na(stroke))
## Convert the result to a data frame with column name "Null count"
result <- data.frame("Null count" = null_counts)
## Print the result
print(result)
## Identify "N/A" values
na_indices <- lapply(stroke, function(x) which(x == "N/A"))
## Replace "N/A" values with NA and count missing values
missing_counts <- sapply(1:ncol(stroke), function(i) {
stroke[[i]][na_indices[[i]]] <- NA
sum(is.na(stroke[[i]]))
})
## Create a data frame with column names and missing counts
result <- data.frame(
Column = names(stroke),
Missing_Count = missing_counts
)
## Print the result
print(result)
## Convert column A to numeric and fill missing values with the mean
stroke$bmi <- as.numeric(as.character(stroke$bmi))
mean_A <- mean(stroke$bmi, na.rm = TRUE)
## Replace missing values in column A with the mean
stroke$bmi[is.na(stroke$bmi)] <- mean_A
## Print the corrected data
print(stroke)
## Identify "N/A" values
na_indices <- lapply(stroke, function(x) which(x == "N/A"))
## Replace "N/A" values with NA and count missing values
missing_counts <- sapply(1:ncol(stroke), function(i) {
stroke[[i]][na_indices[[i]]] <- NA
sum(is.na(stroke[[i]]))
})
## Create a data frame with column names and missing counts
result <- data.frame(
Column = names(stroke),
Missing_Count = missing_counts
)
## Print the result
print(result)
## Count missing values in each column
null_counts <- colSums(is.na(stroke))
## Convert the result to a data frame with column name "Null count"
result <- data.frame("Null count" = null_counts)
## Print the result
print(result)
## Identify "N/A" values
na_indices <- lapply(stroke, function(x) which(x == "N/A"))
## Replace "N/A" values with NA and count missing values
missing_counts <- sapply(1:ncol(stroke), function(i) {
stroke[[i]][na_indices[[i]]] <- NA
sum(is.na(stroke[[i]]))
})
## Create a data frame with column names and missing counts
result <- data.frame(
Column = names(stroke),
Missing_Count = missing_counts
)
## Print the result
print(result)
## Convert column A to numeric and fill missing values with the mean
stroke$bmi <- as.numeric(as.character(stroke$bmi))
mean_A <- mean(stroke$bmi, na.rm = TRUE)
## Replace missing values in column A with the mean
stroke$bmi[is.na(stroke$bmi)] <- mean_A
## Print the corrected data
print(stroke)
## Describe the dataset
glimpse(stroke)
## Find the dimension of the dataset
dim(stroke)
## Count missing values in each column
null_counts <- colSums(is.na(stroke))
## Convert the result to a data frame with column name "Null count"
result <- data.frame("Null count" = null_counts)
## Print the result
print(result)
## Identify "N/A" values
na_indices <- lapply(stroke, function(x) which(x == "N/A"))
## Replace "N/A" values with NA and count missing values
missing_counts <- sapply(1:ncol(stroke), function(i) {
stroke[[i]][na_indices[[i]]] <- NA
sum(is.na(stroke[[i]]))
})
## Create a data frame with column names and missing counts
result <- data.frame(
Column = names(stroke),
Missing_Count = missing_counts
)
## Print the result
print(result)
knitr::opts_chunk$set(echo = TRUE)
stroke <- read_csv('../Data/healthcare-dataset-stroke-data.csv')
## Display head of the dataset
head(stroke)
## Look at the structure of the variables
str(stroke)
## Describe the dataset
glimpse(stroke)
## Find the dimension of the dataset
dim(stroke)
## Count missing values in each column
null_counts <- colSums(is.na(stroke))
## Convert the result to a data frame with column name "Null count"
result <- data.frame("Null count" = null_counts)
## Print the result
print(result)
## Identify "N/A" values
na_indices <- lapply(stroke, function(x) which(x == "N/A"))
## Replace "N/A" values with NA and count missing values
missing_counts <- sapply(1:ncol(stroke), function(i) {
stroke[[i]][na_indices[[i]]] <- NA
sum(is.na(stroke[[i]]))
})
## Create a data frame with column names and missing counts
result <- data.frame(
Column = names(stroke),
Missing_Count = missing_counts
)
## Print the result
print(result)
## Convert column A to numeric and fill missing values with the mean
stroke$bmi <- as.numeric(as.character(stroke$bmi))
mean_A <- mean(stroke$bmi, na.rm = TRUE)
## Replace missing values in column A with the mean
stroke$bmi[is.na(stroke$bmi)] <- mean_A
## Print the corrected data
print(stroke)
## Display summary statistics
summary(stroke)
## Plot the bar chart for the target variable
barplot(table(stroke$stroke) / length(stroke$stroke), col = c('red', 'green'), main = "Distribution of target variable", ylab = "Proportion", ylim = c(0, 1))
## Density plot for age
plot(density(stroke$age), main = "Density Plot of Age", xlab = "Age", col = "blue", lwd = 2)
# Add a rug plot for individual data points
rug(stroke$age, col = "red")
## Density plot for age
plot(density(stroke$avg_glucose_level), main = "Density Plot of Avarage Glucose level", xlab = "avg_glucose_level", col = "blue", lwd = 2)
## Add a rug plot for individual data points
rug(stroke$avg_glucose_level, col = "red")
## Density plot for age
plot(density(stroke$bmi), main = "Density Plot of BMI", xlab = "BMI", col = "blue", lwd = 2)
## Add a rug plot for individual data points
rug(stroke$bmi, col = "red")
## Boxplot for age
boxplot(stroke$age, main = "Boxplot of Age", col = "lightgreen", border = "black")
## Boxplot for avg_glucose_level
boxplot(stroke$avg_glucose_level, main = "Boxplot of Avg Glucose Level", col = "lightblue", border = "black")
## Boxplot for bmi
boxplot(stroke$bmi, main = "Boxplot of BMI", col = "lightcoral", border = "black")
## Create a pie chart for gender
gender_counts <- table(stroke$gender)
gender_percentages <- round(prop.table(gender_counts) * 100, 1)
pie(gender_counts, labels = paste(names(gender_counts), "\n", gender_percentages, "%"), main = "Distribution of Gender", col = rainbow(length(gender_counts)))
## Create a pie chart for ever_married
married_counts <- table(stroke$ever_married)
married_percentages <- round(prop.table(married_counts) * 100, 1)
pie(married_counts, labels = paste(names(married_counts), "\n", married_percentages, "%"), main = "Distribution of Marital Status", col = rainbow(length(married_counts)))
## Create a pie chart for work_type
work_counts <- table(stroke$work_type)
work_percentages <- round(prop.table(work_counts) * 100, 1)
pie(work_counts, labels = paste(names(work_counts), "\n", work_percentages, "%"), main = "Distribution of Work Type", col = rainbow(length(work_counts)))
## Create a pie chart for Residence_type
residence_counts <- table(stroke$Residence_type)
residence_percentages <- round(prop.table(residence_counts) * 100, 1)
pie(residence_counts, labels = paste(names(residence_counts), "\n", residence_percentages, "%"), main = "Distribution of Residence Type", col = rainbow(length(residence_counts)))
## Create a pie chart for Residence_type
smoke_counts <- table(stroke$smoking_status)
smoke_percentages <- round(prop.table(smoke_counts) * 100, 1)
pie(smoke_counts, labels = paste(names(smoke_counts), "\n", smoke_percentages, "%"), main = "Distribution of Smoking status", col = rainbow(length(residence_counts)))
## Boxplot for age with respect to stroke
boxplot(age ~ stroke, data = stroke, main = "Age Distribution by Stroke", xlab = "Stroke", ylab = "Age", col = c("lightgreen", "lightcoral"))
## Boxplot for avg_glucose_level with respect to stroke
boxplot(avg_glucose_level ~ stroke, data = stroke, main = "Avg Glucose Level by Stroke", xlab = "Stroke", ylab = "Avg Glucose Level", col = c("lightgreen", "lightcoral"))
## Boxplot for bmi with respect to stroke
boxplot(bmi ~ stroke, data = stroke, main = "BMI Distribution by Stroke", xlab = "Stroke", ylab = "BMI", col = c("lightgreen", "lightcoral"))
## Function to calculate percentages and create bar plots with different colors
plot_categorical_variable <- function(variable, title, colors) {
percentages <- prop.table(table(stroke[[variable]], stroke$stroke), margin = 2) * 100
ggplot(stroke, aes(x = get(variable), fill = as.factor(stroke))) +
geom_bar(position = "fill", stat = "count") +
scale_y_continuous(labels = scales::percent_format(scale = 1)) +
labs(title = title, x = variable, y = "Percentage") +
scale_fill_manual(values = colors) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
}
## Create bar plots for each categorical variable with different colors
plot_categorical_variable("gender", "Distribution of Gender by Stroke", c("skyblue", "pink"))
plot_categorical_variable("ever_married", "Distribution of Marital Status by Stroke", c("lightgreen", "lightcoral"))
plot_categorical_variable("work_type", "Distribution of Work Type by Stroke", c("lightblue", "salmon"))
plot_categorical_variable("Residence_type", "Distribution of Residence Type by Stroke", c("lightgoldenrod", "lightsalmon"))
## Calculate the correlation matrix
cor_matrix <- cor(stroke[, c("age", "avg_glucose_level", "bmi")])
## Plot the correlation matrix with an attractive color scale
corrplot(cor_matrix, method = "color", col = colorRampPalette(c("darkblue", "white", "darkred"))(100),
addCoef.col = "black", tl.cex = 0.8, tl.srt = 45)
## Select numerical variables for correlation analysis
numerical_variables <- c("age", "avg_glucose_level", "bmi")
## Create an empty data frame to store correlation results
cor_data_long <- data.frame()
## Loop through numerical variables and calculate correlations
for (variable in numerical_variables) {
correlation_result <- cor.test(stroke[[variable]], stroke$stroke, method = "spearman")
## Append results to the data frame
cor_data_long <- rbind(cor_data_long, data.frame(
variable = variable,
correlation = correlation_result$estimate,
p_value = correlation_result$p.value
))
}
## Create a bar plot
ggplot(cor_data_long, aes(x = variable, y = correlation, fill = variable)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Correlation with Stroke", x = "Variable", y = "Correlation") +
scale_fill_manual(values = c("lightblue", "lightgreen", "lightcoral")) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
## Extract features (X) and target variable (y)
X <- stroke[, !(names(stroke) %in% c("stroke"))]
y <- stroke$stroke
## Data preprocessing (handle missing values, encode categorical variables, etc.)
## Split the dataset into training and testing sets
set.seed(42)  # for reproducibility
split_index <- createDataPartition(y, p = 0.8, list = FALSE)
train_data <- stroke[split_index, ]
test_data <- stroke[-split_index, ]
## Create and train the Naive Bayes model
model <- naiveBayes(stroke ~ ., data = train_data, laplace = 1)
model
# laplace smoothing, adjust as needed
# ...
## Make predictions on the testing set
predictions <- predict(model, newdata = test_data)
## Evaluate the model
conf_matrix <- table(predictions, test_data$stroke)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Accuracy:", accuracy, "\n")
## Display confusion matrix for more detailed metrics
print(conf_matrix)
# ... (model training and evaluation code)
# Evaluate the model
conf_matrix <- table(predictions, test_data$stroke)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- conf_matrix[2, 2] / sum(conf_matrix[, 2])
recall <- conf_matrix[2, 2] / sum(conf_matrix[2, ])
f1_score <- 2 * (precision * recall) / (precision + recall)
cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")
cat("F1 Score:", f1_score, "\n")
## Assuming 'predictions' and 'test_data$stroke' are probabilities
roc_curve <- roc(test_data$stroke, as.numeric(predictions == 1))
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)
# Compute the percentage for each category
percentage_stroke <- table(stroke$stroke) / length(stroke$stroke) * 100
# Plot the bar chart with percentages
barplot(percentage_stroke, col = c('red', 'green'),
main = "Distribution of target variable",
ylab = "Percentage",
ylim = c(0, 100),
names.arg = c('No Stroke', 'Stroke'),
cex.names = 0.8)
# Compute the percentage for each category
percentage_stroke <- table(stroke$stroke) / length(stroke$stroke) * 100
# Plot the bar chart with percentages
barplot(percentage_stroke, col = c('red', 'green'),
main = "Distribution of target variable",
ylab = "Percentage",
ylim = c(0, 100),
names.arg = c('No Stroke', 'Stroke'),
cex.names = 0.8)
# Compute the percentage for each category
percentage_stroke <- table(stroke$stroke) / length(stroke$stroke) * 100
# Plot the bar chart with percentages
barplot(percentage_stroke, col = c('red', 'green'),
main = "Distribution of target variable",
ylab = "Percentage",
ylim = c(0, 100),
names.arg = c('No Stroke', 'Stroke'),
cex.names = 0.8)
# Display percentage labels on the bars
text(x = barplot(percentage_stroke, col = c('red', 'green'), plot = FALSE),
y = percentage_stroke + 2,
labels = sprintf("%.1f%%", percentage_stroke),
pos = 3,
cex = 0.8)
# Compute the percentage for each category
percentage_stroke <- table(stroke$stroke) / length(stroke$stroke) * 100
# Plot the bar chart with percentages
barplot(percentage_stroke, col = c('red', 'green'),
main = "Distribution of target variable",
ylab = "Percentage",
ylim = c(0, 100),
names.arg = c('No Stroke', 'Stroke'),
cex.names = 0.8)
# Display percentage labels on the bars
text(x = barplot(percentage_stroke, col = c('red', 'green'), plot = FALSE),
y = percentage_stroke + 2,
labels = sprintf("%.1f%%", percentage_stroke),
pos = 3,
cex = 0.8)
# Assuming 'stroke' is your data frame and 'stroke' is the target variable
# Replace 'stroke' with the actual name of your data frame and target variable
# Compute the percentage for each category
percentage_stroke <- table(stroke$stroke) / length(stroke$stroke) * 100
# Plot the bar chart with percentages
barplot(percentage_stroke, col = c('red', 'green'),
main = "Distribution of target variable",
ylab = "Percentage",
ylim = c(0, 100),
names.arg = c('No Stroke (0)', 'Stroke (1)'),
cex.names = 0.8)
# Display percentage labels on the bars
text(x = barplot(percentage_stroke, col = c('red', 'green'), plot = FALSE),
y = percentage_stroke + 2,
labels = sprintf("%.1f%%", percentage_stroke),
pos = 3,
cex = 0.8)
# Calculate percentages
total <- sum(stroke$stroke)
percentages <- (data / total) * 100
# Calculate percentages
total <- sum(stroke$stroke)
percentages <- (data / total) * 100
# Calculate percentages
total <- sum(stroke$stroke)
percentages <- (data / total) * 100
ggplot(stroke, aes(x = age, y = avg_glucose_level)) +
geom_point()
ggplot(stroke, aes(x = age, y = bmi)) +
geom_point()
ggplot(stroke, aes(x =bmi , y = age)) +
geom_point()
ggplot(stroke, aes(x =age , y = bmi)) +
geom_point()
# Assuming you have a vector with 0s and 1s
data <- c(0, 1, 1, 0, 1, 0, 0, 1, 1, 0)
# Calculate the percentage of each value
percentage_0 <- (sum(stroke$stroke == 0) / length(stroke$stroke)) * 100
percentage_1 <- (sum(stroke$stroke == 1) / length(stroke$stroke)) * 100
# Create a bar plot
bar_heights <- c(percentage_0, percentage_1)
bar_names <- c('0', '1')
barplot(bar_heights, names.arg = bar_names, col = c('red', 'green'),
xlab = 'Values', ylab = 'Percentage',
main = 'Percentage of 0s and 1s')
percentage_0
# Calculate the percentage of each value
percentage_0 <- (sum(stroke$stroke == 0) / length(stroke$stroke)) * 100
percentage_1 <- (sum(stroke$stroke == 1) / length(stroke$stroke)) * 100
# Create a bar plot
bar_heights <- c(percentage_0, percentage_1)
bar_names <- c('0', '1')
# Plot the bar graph
barplot(bar_heights, names.arg = bar_names, col = c('red', 'green'),
xlab = 'Values', ylab = 'Percentage',
main = 'Percentage of 0s and 1s')
# Add percentage values on top of each bar
text(seq_along(bar_heights), bar_heights, labels = sprintf("%.1f%%", bar_heights),
pos = 3, cex = 0.8, col = 'black', font = 2)
# Calculate the percentage of each value
percentage_0 <- (sum(stroke$stroke == 0) / length(stroke$stroke)) * 100
percentage_1 <- (sum(stroke$stroke == 1) / length(stroke$stroke)) * 100
# Create a bar plot
bar_heights <- c(percentage_0, percentage_1)
bar_names <- c('0', '1')
# Plot the bar graph
barplot(bar_heights, names.arg = bar_names, col = c('red', 'green'),
xlab = 'Values', ylab = 'Percentage',
main = 'Percentage of 0s and 1s')
# Add percentage values on top of each bar
text(seq_along(bar_heights), bar_heights, labels = sprintf("%.1f%%", bar_heights),
pos = 3, cex = 0.8, col = 'black', font = 2)
# Add percentage values on top of each bar
text(seq_along(bar_heights), bar_heights, labels = sprintf("%.1f%%", bar_heights),
pos = 3, cex = 0.8, col = 'black', font = 3)
# Calculate the percentage of each value
percentage_0 <- (sum(stroke$stroke == 0) / length(stroke$stroke)) * 100
percentage_1 <- (sum(stroke$stroke == 1) / length(stroke$stroke)) * 100
# Create a bar plot
bar_heights <- c(percentage_0, percentage_1)
bar_names <- c('0', '1')
# Plot the bar graph
barplot(bar_heights, names.arg = bar_names, col = c('red', 'green'),
xlab = 'Values', ylab = 'Percentage',
main = 'Percentage of 0s and 1s')
# Add percentage values on top of each bar
text(seq_along(bar_heights), bar_heights, labels = sprintf("%.1f%%", bar_heights),
pos = 3, cex = 0.8, col = 'black', font = 3)
# Calculate the percentage of each value
percentage_0 <- (sum(stroke$stroke == 0) / length(stroke$stroke)) * 100
percentage_1 <- (sum(stroke$stroke == 1) / length(stroke$stroke)) * 100
# Create a bar plot
bar_heights <- c(percentage_0, percentage_1)
bar_names <- c('0', '1')
# Plot the bar graph
barplot(bar_heights, names.arg = bar_names, col = c('red', 'green'),
xlab = 'Values', ylab = 'Percentage',
main = 'Percentage of 0s and 1s')
# Add percentage values on top of each bar
text(seq_along(bar_heights), bar_heights, labels = sprintf("%.1f%%", bar_heights),
pos = 3, cex = 0.8, col = 'black', font = 1)
knitr::opts_chunk$set(echo = TRUE)
# Assuming you have a new dataset called 'new_data'
new_data <- data.frame(
id = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10),  # Replace with actual values
gender = c("Male", "Female", "Male", "Female", "Female", "Male", "Male", "Female", "Female", "Female"),
age = c(67, 61, 80, 49, 79, 81, 74, 69, 59, 78),  # Replace with actual values
hypertension = c(0, 0, 0, 0, 1, 0, 1, 0, 0, 0),  # Replace with actual values
heart_disease = c(1, 0, 1, 0, 0, 0, 1, 0, 0, 0),  # Replace with actual values
ever_married = c("Yes", "Yes", "Yes", "Yes", "Yes", "Yes", "Yes", "No", "Yes", "Yes"),
work_type = c("Private", "Self-employed", "Private", "Private", "Self-employed", "Private", "Private", "Private", "Private", "Private"),
Residence_type = c("Urban", "Rural", "Rural", "Urban", "Rural", "Urban", "Rural", "Urban", "Rural", "Urban"),
avg_glucose_level = c(228.69, 202.21, 105.92, 171.23, 174.12, 186.21, 70.09, 94.39, 76.15, 58.57),  # Replace with actual values
bmi = c(36.6, 28.89324, 32.5, 34.4, 24, 29, 27.4, 22.8, 28.89324, 24.2),  # Replace with actual values
smoking_status = c("formerly smoked", "never smoked", "never smoked", "smokes", "never smoked", "formerly smoked", "never smoked", "never smoked", "Unknown", "Unknown")
)
# Make predictions on the new data
new_predictions <- predict(model, new_data, type = "class")
knitr::opts_chunk$set(echo = TRUE)
# Assuming you have prior and conditional probabilities from your Naive Bayes model
prior_prob_1 <- 0.1  # Replace with the actual prior probability for stroke = 1
prior_prob_0 <- 0.9  # Replace with the actual prior probability for stroke = 0
# Conditional probabilities for each predictor variable given stroke = 1
cond_prob_1 <- c(0.2, 0.4, 0.3, 0.6, 0.7, 0.5, 0.8, 0.4, 0.3, 0.6, 0.5)
# Conditional probabilities for each predictor variable given stroke = 0
cond_prob_0 <- c(0.8, 0.6, 0.7, 0.4, 0.3, 0.5, 0.2, 0.6, 0.7, 0.4, 0.5)
# Assuming you have a new data point for prediction
new_data_point <- c(9046, "Male", 67.00, 0, 1, "Yes", "Private", "Urban", 228.69, 36.60000, "formerly smoked")
# Calculate the likelihoods for stroke = 1 and stroke = 0
likelihood_1 <- prod(cond_prob_1 * ifelse(is.numeric(new_data_point), dnorm(new_data_point, mean = mean(train_data[train_data$stroke == 1, colnames(train_data) == names(new_data_point)], na.rm = TRUE), sd = sd(train_data[train_data$stroke == 1, colnames(train_data) == names(new_data_point)], na.rm = TRUE)), ifelse(train_data[train_data$stroke == 1, colnames(train_data) == names(new_data_point)] == new_data_point, 1, 0)))
knitr::opts_chunk$set(echo = TRUE)
# Assuming you have a new data point for prediction
new_data_point <- data.frame(
id = 9046, gender = "Male", age = 67.00, hypertension = 0, heart_disease = 1,
ever_married = "Yes", work_type = "Private", Residence_type = "Urban",
avg_glucose_level = 228.69, bmi = 36.60000, smoking_status = "formerly smoked"
)
# Extract the numeric and non-numeric columns
numeric_cols <- sapply(new_data_point, is.numeric)
non_numeric_cols <- setdiff(names(new_data_point), names(new_data_point)[numeric_cols])
# Calculate the likelihoods for stroke = 1 and stroke = 0 for numeric variables
likelihood_1_numeric <- prod(dnorm(new_data_point[, numeric_cols],
mean = colMeans(train_data[train_data$stroke == 1, numeric_cols], na.rm = TRUE),
sd = apply(train_data[train_data$stroke == 1, numeric_cols], 2, sd, na.rm = TRUE)))
knitr::opts_chunk$set(echo = TRUE)
# Assuming you have a new data point for prediction
new_data_point <- data.frame(
id = 9046, gender = "Male", age = 67.00, hypertension = 0, heart_disease = 1,
ever_married = "Yes", work_type = "Private", Residence_type = "Urban",
avg_glucose_level = 228.69, bmi = 36.60000, smoking_status = "formerly smoked"
)
# Extract the numeric and non-numeric columns
numeric_cols <- sapply(new_data_point, is.numeric)
non_numeric_cols <- setdiff(names(new_data_point), names(new_data_point)[numeric_cols])
# Calculate the likelihoods for stroke = 1 and stroke = 0 for numeric variables
likelihood_1_numeric <- prod(dnorm(new_data_point[, numeric_cols],
mean = colMeans(train_data[train_data$stroke == 1, numeric_cols], na.rm = TRUE),
sd = apply(train_data[train_data$stroke == 1, numeric_cols], 2, sd, na.rm = TRUE)))
